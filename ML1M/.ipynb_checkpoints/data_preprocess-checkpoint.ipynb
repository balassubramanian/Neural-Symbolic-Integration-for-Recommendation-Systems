{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  itemId\n",
       "0       1    1193\n",
       "1       1     661\n",
       "2       1     914\n",
       "3       1    3408\n",
       "4       1    2355"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv('./ratings.dat', sep='::', names=[\"userId\", \"itemId\", \"rating\", \"timestamp\"], engine='python')\n",
    "rating_df.drop(columns=['timestamp'], inplace=True)\n",
    "rating_df.drop(columns=['rating'], inplace=True)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemId                               title                        genres\n",
       "0       1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1       2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2       3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3       4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4       5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_df = pd.read_csv('./movies.dat', sep='::', names=['itemId', 'title', 'genres'], engine='python')\n",
    "item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_genre_dict = dict()\n",
    "for i in range(len(item_df)):\n",
    "    genre_str = item_df.at[i, 'genres']\n",
    "    genre_list = genre_str.split('|')\n",
    "    item_genre_dict[item_df.at[i, 'itemId']] = genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rating_df))\n",
    "rating_df.drop_duplicates(subset =['itemId', 'userId'], \n",
    "                          keep = 'first', inplace = True)\n",
    "print(len(rating_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_set = set(rating_df['itemId'].unique())\n",
    "user_set = set(rating_df['userId'].unique())\n",
    "print('item num = ' + str(len(item_set)))\n",
    "print('user num = ' + str(len(user_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number for each genre and sort\n",
    "import operator\n",
    "genre_count = dict()\n",
    "for l in item_genre_dict:\n",
    "    for g in item_genre_dict[l]:\n",
    "        if not g in genre_count:\n",
    "            genre_count[g] = 1\n",
    "        else:\n",
    "            genre_count[g] += 1\n",
    "\n",
    "genre_count_sorted = sorted(genre_count.items(), key=operator.itemgetter(1), reverse=True)\n",
    "genre_count_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.reset_index(drop=True, inplace=True)\n",
    "rdf_backup = copy.copy(rating_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = copy.copy(rdf_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# iteratively remove items and users with less than 2 reviews\n",
    "rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "while np.min(rdf['user_freq']) <= 9:\n",
    "    rdf.drop(rdf.index[rdf['user_freq'] <= 9], inplace=True)\n",
    "    rdf.reset_index(drop=True, inplace=True)\n",
    "    rdf['item_freq'] = rdf.groupby('itemId')['itemId'].transform('count')\n",
    "    rdf.drop(rdf.index[rdf['item_freq'] <= 9], inplace=True)\n",
    "    rdf.reset_index(drop=True, inplace=True)\n",
    "    rdf['user_freq'] = rdf.groupby('userId')['userId'].transform('count')\n",
    "    rdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = rdf['itemId'].unique()\n",
    "user_list = rdf['userId'].unique()\n",
    "print('item num = ' + str(len(item_list)))\n",
    "print('user num = ' + str(len(user_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the user and item str id->int id dict\n",
    "i = 0\n",
    "user_old2new_id_dict = dict()\n",
    "for u in user_list:\n",
    "    if not u in user_old2new_id_dict:\n",
    "        user_old2new_id_dict[u] = i\n",
    "        i += 1\n",
    "j = 0\n",
    "item_old2new_id_dict = dict()\n",
    "for i in item_list:\n",
    "    if not i in item_old2new_id_dict:\n",
    "        item_old2new_id_dict[i] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sparsity: ' + str(len(rdf) * 1.0 / (len(user_list) * len(item_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the str id of items in item_df to int id\n",
    "for i in range(len(item_df)):\n",
    "    if item_df.at[i, 'itemId'] not in item_old2new_id_dict:\n",
    "        item_df.drop([i], axis=0, inplace=True)\n",
    "    else:\n",
    "        item_df.at[i, 'itemId'] = item_old2new_id_dict[item_df.at[i, 'itemId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df for rdf with int id for user and item\n",
    "for i in range(len(rdf)):\n",
    "    rdf.at[i, 'userId'] = user_old2new_id_dict[rdf.at[i, 'userId']]\n",
    "    rdf.at[i, 'itemId'] = item_old2new_id_dict[rdf.at[i, 'itemId']]\n",
    "item_list = rdf['itemId'].unique()\n",
    "user_list = rdf['userId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the df of train, vali, and test df\n",
    "rdf.reset_index(inplace=True, drop=True)\n",
    "train_df = rdf.copy()\n",
    "\n",
    "train_ratio = 0.7\n",
    "vali_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "vali_size = int(vali_ratio * len(rdf))\n",
    "test_size = int(test_ratio * len(rdf))\n",
    "\n",
    "vali_idx = np.random.choice(np.arange(len(train_df)), \n",
    "                            vali_size,\n",
    "                            replace=False).tolist()\n",
    "vali_df = train_df.copy()\n",
    "vali_df = vali_df.loc[vali_idx]\n",
    "train_df.drop(vali_idx, axis=0, inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_idx = np.random.choice(np.arange(len(train_df)), \n",
    "                            test_size,\n",
    "                            replace=False).tolist()\n",
    "test_df = train_df.copy()\n",
    "test_df = test_df.loc[test_idx]\n",
    "train_df.drop(test_idx, axis=0, inplace=True)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the popularity of items, stored in item_df\n",
    "item_pop = np.array(train_df['itemId'].value_counts())\n",
    "item_pop_id = np.array(train_df['itemId'].value_counts().index)\n",
    "item_df['pop'] = 0\n",
    "for i in range(len(item_pop_id)):\n",
    "    item_df.at[item_df['itemId'] == item_pop_id[i], 'pop'] = item_pop[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(columns=['user_freq', 'item_freq'], inplace=True)\n",
    "test_df.drop(columns=['user_freq', 'item_freq'], inplace=True)\n",
    "vali_df.drop(columns=['user_freq', 'item_freq'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "vali_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate list of items users like in train, vali, test sets for each user\n",
    "\n",
    "num_item = len(item_list)\n",
    "num_user = len(user_list)\n",
    "\n",
    "user_train_like = []\n",
    "user_test_like = [] \n",
    "user_vali_like = []  \n",
    "\n",
    "train_array = train_df[['userId', 'itemId']].values\n",
    "vali_array = vali_df[['userId', 'itemId']].values\n",
    "test_array = test_df[['userId', 'itemId']].values\n",
    "\n",
    "for u in user_list:\n",
    "    train_like = (train_array[list(np.where(train_array[:, 0] == u)[0]), 1]).astype(int)\n",
    "    vali_like = (vali_array[list(np.where(vali_array[:, 0] == u)[0]), 1]).astype(int)\n",
    "    test_like = (test_array[list(np.where(test_array[:, 0] == u)[0]), 1]).astype(int)\n",
    "    user_train_like.append(train_like)\n",
    "    user_vali_like.append(vali_like)\n",
    "    user_test_like.append(test_like)\n",
    "    \n",
    "np.save('./user_train_like.npy', np.array(user_train_like))\n",
    "np.save('./user_vali_like.npy', np.array(user_vali_like))\n",
    "np.save('./user_test_like.npy', np.array(user_test_like))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./train_df.csv', index=False)\n",
    "vali_df.to_csv('./vali_df.csv', index=False)\n",
    "test_df.to_csv('./test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df.reset_index(drop=True, inplace=True)\n",
    "movie_df = item_df.copy()\n",
    "item_df.drop(columns=['title', 'genres'], inplace=True)\n",
    "item_df.to_csv('./item_df.csv', index=False)\n",
    "movie_df.to_csv('./movie_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./info.pkl', 'wb') as f:\n",
    "    pickle.dump({'num_user': num_user, 'num_item': num_item}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
